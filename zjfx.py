# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
import statsmodels.api as sm
from scipy import stats
from itertools import combinations
from math import sqrt
from io import BytesIO
import base64
import zipfile
import datetime as dt
import os

# ML / utils
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve
from sklearn.neighbors import NearestNeighbors

matplotlib.rcParams['axes.unicode_minus'] = False

st.set_page_config(page_title="è´¨æ£€ä¸æ»¡æ„åº¦åˆ†æ", layout="wide")
st.title("è´¨æ£€-æ»¡æ„åº¦åˆ†æ")

# ====================== å›¾è¡¨/è¡¨æ ¼æ³¨å†Œå™¨ï¼ˆç”¨äºå¯¼å‡ºï¼‰ ======================
fig_registry = {}   # {name: matplotlib.figure.Figure}
table_registry = {} # {name: pandas.DataFrame}
text_registry = {}  # {name: str}

def register_fig(name, fig):
    fig_registry[name] = fig

def register_table(name, df):
    table_registry[name] = df.copy()

def register_text(name, txt):
    text_registry[name] = str(txt)

# ============ å°å·¥å…·å‡½æ•° ============
def safe_to_int(x):
    if pd.isna(x): return 0
    s = str(x).strip().lower()
    if s in ["1", "1.0", "true", "t", "y", "yes"]: return 1
    if s in ["0", "0.0", "false", "f", "n", "no"]: return 0
    return 0

def plot_spc(series, title="SPC Chart"):
    x = np.arange(len(series))
    mean = np.mean(series)
    std = np.std(series, ddof=1) if len(series) > 1 else 0
    ucl = mean + 3*std
    lcl = mean - 3*std
    fig, ax = plt.subplots(figsize=(9,4.5), dpi=140)
    ax.plot(x, series, marker="o", linewidth=1.8, label="Rate")
    ax.axhline(mean, linestyle="--", color="gray", label="Center")
    if std>0:
        ax.axhline(ucl, linestyle="--", color="red", label="UCL (+3Ïƒ)")
        ax.axhline(lcl, linestyle="--", color="red", label="LCL (-3Ïƒ)")
    ax.set_title(title)
    ax.set_xlabel("Index")
    ax.set_ylabel("Rate")
    ax.legend()
    ax.grid(alpha=0.25, linestyle="--", linewidth=0.5)
    return fig

def benjamini_hochberg(pvals, alpha=0.05):
    p = np.array(pvals)
    n = len(p)
    order = np.argsort(p)
    ranked = p[order]
    crit = alpha * np.arange(1, n+1) / n
    passed = ranked <= crit
    if not passed.any():
        return np.zeros(n, dtype=bool)
    k = np.max(np.where(passed))
    thresh = ranked[k]
    return p <= thresh

def bootstrap_diff_rate(a, b, n_boot=1000, seed=42):
    rng = np.random.default_rng(seed)
    diffs = []
    a = np.array(a); b = np.array(b)
    for _ in range(n_boot):
        aa = rng.choice(a, size=len(a), replace=True)
        bb = rng.choice(b, size=len(b), replace=True)
        diffs.append(aa.mean() - bb.mean())
    lo, hi = np.percentile(diffs, [2.5, 97.5])
    return np.mean(diffs), lo, hi

# ====================== ä¸Šä¼  ======================
uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ å¤šä¸ªè´¨æ£€æ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒ Excel / CSVï¼Œå¯å¤šé€‰ï¼‰",
    type=["xlsx", "csv"],
    accept_multiple_files=True
)

if uploaded_files:
    # è¯»å–
    all_dfs = []
    for uploaded_file in uploaded_files:
        try:
            if uploaded_file.name.lower().endswith(".csv"):
                df_tmp = pd.read_csv(uploaded_file)
            else:
                df_tmp = pd.read_excel(uploaded_file)
            df_tmp["source_file"] = uploaded_file.name
            all_dfs.append(df_tmp)
        except Exception as e:
            st.error(f"âŒ æ–‡ä»¶ {uploaded_file.name} è¯»å–å¤±è´¥: {e}")
    df = pd.concat(all_dfs, ignore_index=True)
    st.success(f"âœ… æˆåŠŸåŠ è½½ {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼Œå…± {len(df)} æ¡è®°å½•")

    # æ¸…æ´—
    st.subheader("æ•°æ®æ¸…æ´—ä¸é€»è¾‘å¤„ç†")
    required_cols = ["score", "solution", "service_attitude", "response_speed", "case_classification"]
    for c in required_cols:
        if c not in df.columns:
            st.error(f"âŒ ç¼ºå°‘å­—æ®µï¼š{c}")
            st.stop()
    df = df.replace("-", np.nan)
    df = df[df["score"].notna()].copy()
    df["response_speed"] = df["response_speed"].fillna(1)

    pass_cols = ["solution", "service_attitude", "response_speed", "case_classification"]
    for col in pass_cols:
        df[col] = df[col].apply(safe_to_int)
    df["satisfied"] = np.where(df["score"] >= 4, 1, 0)
    df["overall_pass"] = np.where((df[pass_cols].sum(axis=1) == 4), 1, 0)

    st.markdown("""
    **æ¸…æ´—é€»è¾‘ï¼š** å‰”é™¤æœªæ‰“åˆ†ï¼›'-' è§†ä¸ºç©ºï¼›`response_speed` ç©ºæŒ‰é€šè¿‡ï¼›å››é¡¹å…¨ 1 ä¸ºæ•´ä½“é€šè¿‡ï¼›æ‰“åˆ†â‰¥4 ä¸ºæ»¡æ„ã€‚
    """)

    # æ¦‚è§ˆ
    st.subheader("å„é¡¹é€šè¿‡ç‡ä¸æ»¡æ„ç‡")
    summary = df[pass_cols + ["overall_pass", "satisfied"]].mean().to_frame("rate")
    summary["rate"] = summary["rate"].apply(lambda x: round(x*100,2))
    st.dataframe(summary.T.style.format("{:.2f}%"))
    register_table("summary_rates", summary)

    # ç›¸å…³æ€§
    st.subheader("ç›¸å…³æ€§åˆ†æï¼ˆPearsonï¼‰")
    fig_corr, ax_corr = plt.subplots(figsize=(6.5, 4.5), dpi=140)
    sns.heatmap(df[pass_cols + ["satisfied"]].corr(), annot=True, cmap="YlGnBu", fmt=".2f", ax=ax_corr)
    ax_corr.set_title("Correlation between QC Items and Satisfaction", fontsize=11)
    st.pyplot(fig_corr)
    register_fig("corr_matrix", fig_corr)

    # tæ£€éªŒ
    st.subheader("æ˜¾è‘—æ€§å·®å¼‚åˆ†æï¼ˆt æ£€éªŒï¼šé€šè¿‡ç»„ vs æœªé€šè¿‡ç»„æ»¡æ„ç‡ï¼‰")
    t_rows = []
    for col in pass_cols:
        p1 = df[df[col]==1]["satisfied"]; p0 = df[df[col]==0]["satisfied"]
        if len(p1)>2 and len(p0)>2:
            t, p = stats.ttest_ind(p1, p0, equal_var=False)
            diff = p1.mean()-p0.mean()
            t_rows.append([col, round(p1.mean(),3), round(p0.mean(),3), round(diff,3), round(p,4)])
    result_df = pd.DataFrame(t_rows, columns=["æŒ‡æ ‡é¡¹","é€šè¿‡ç»„æ»¡æ„ç‡","æœªé€šè¿‡ç»„æ»¡æ„ç‡","å·®å¼‚","på€¼"])
    st.dataframe(result_df)
    register_table("t_test", result_df)

    # Logistic å•é¡¹
    st.subheader("Logistic å›å½’åˆ†æï¼ˆå•é¡¹ï¼‰")
    X = sm.add_constant(df[pass_cols]); y = df["satisfied"]
    logit_model = sm.Logit(y, X).fit(disp=False)
    coef_df = pd.DataFrame({
        "æŒ‡æ ‡é¡¹": logit_model.params.index[1:],
        "å›å½’ç³»æ•°": logit_model.params.values[1:],
        "på€¼": logit_model.pvalues.values[1:]
    }).sort_values("å›å½’ç³»æ•°", ascending=False)
    st.dataframe(coef_df.style.background_gradient(cmap="RdYlGn", axis=0))
    register_table("logit_single", coef_df)

    fig_bar, ax_bar = plt.subplots(figsize=(7.5, 4.5), dpi=140)
    sns.barplot(x="å›å½’ç³»æ•°", y="æŒ‡æ ‡é¡¹", data=coef_df, ax=ax_bar)
    ax_bar.axvline(0, color="gray", linestyle="--")
    ax_bar.set_xlabel("Regression Coefficient", fontsize=10)
    ax_bar.set_ylabel("QC Item", fontsize=10)
    ax_bar.set_title("Impact of QC Items on Satisfaction", fontsize=11)
    st.pyplot(fig_bar)
    register_fig("logit_coef_bar", fig_bar)

    # ä¸¤ä¸¤äº¤äº’
    st.subheader("ä¸¤ä¸¤ç»„åˆå¯¹æ»¡æ„åº¦çš„å½±å“ï¼ˆäº¤äº’é¡¹åˆ†æï¼‰")
    comb_results, interaction_cols = [], []
    for i in range(len(pass_cols)):
        for j in range(i+1, len(pass_cols)):
            c1, c2 = pass_cols[i], pass_cols[j]
            name = f"{c1} Ã— {c2}"
            df[name] = df[c1]*df[c2]
            interaction_cols.append(name)
            grp = df.groupby(name)["satisfied"].agg(["mean","count"]).reset_index()
            if len(grp)==2:
                diff = grp.loc[grp[name]==1,"mean"].values[0]-grp.loc[grp[name]==0,"mean"].values[0]
                t, p = stats.ttest_ind(df[df[name]==1]["satisfied"], df[df[name]==0]["satisfied"], equal_var=False)
                comb_results.append([name, round(grp.loc[grp[name]==1,"mean"].values[0],3),
                                     round(grp.loc[grp[name]==0,"mean"].values[0],3),
                                     round(diff,3), round(p,4)])
    combo_df = pd.DataFrame(comb_results, columns=["ç»„åˆ","äº¤äº’é€šè¿‡ç»„æ»¡æ„ç‡","æœªäº¤äº’ç»„æ»¡æ„ç‡","å·®å¼‚","på€¼"])
    st.dataframe(combo_df)
    register_table("interaction_ttest", combo_df)

    st.subheader("äº¤äº’é¡¹ Logistic å›å½’")
    X_interact = sm.add_constant(df[pass_cols+interaction_cols])
    logit_interact = sm.Logit(y, X_interact).fit(disp=False)
    coef_inter_df = pd.DataFrame({
        "å˜é‡": logit_interact.params.index[1:],
        "å›å½’ç³»æ•°": logit_interact.params.values[1:],
        "på€¼": logit_interact.pvalues.values[1:]
    }).sort_values("å›å½’ç³»æ•°", ascending=False)
    st.dataframe(coef_inter_df.style.background_gradient(cmap="RdYlGn", axis=0))
    register_table("logit_interactions", coef_inter_df)

    # ========= è¿›é˜¶æ¨¡å—ï¼ˆå¼€å…³ï¼‰ =========
    st.markdown("---")
    st.header("è¿›é˜¶åˆ†ææ¨¡å—ï¼ˆæŒ‰éœ€å¼€å¯ï¼‰")

    # 1) æ•°æ®è´¨é‡ / ç¼ºå¤±æ¨¡å¼
    if st.checkbox("â‘  æ•°æ®è´¨é‡ä¸ç¼ºå¤±æ¨¡å¼æŠ¥å‘Š"):
        st.subheader("å­—æ®µç¼ºå¤±ç‡ï¼ˆ%ï¼‰")
        miss = df.isna().mean().sort_values(ascending=False)*100
        st.dataframe(miss.to_frame("missing_%").style.format("{:.2f}"))
        register_table("missing_report", miss.to_frame("missing_%"))
        if "satisfied" in df.columns:
            fig = plot_spc(df["satisfied"].rolling(20, min_periods=5).mean().dropna(), "SPC: Satisfaction Rolling Mean")
            st.pyplot(fig)
            register_fig("spc_satisfied", fig)

    # 2) å¤šé‡å…±çº¿æ€§ VIF
    if st.checkbox("â‘¡ å¤šé‡å…±çº¿æ€§è¯Šæ–­ï¼ˆVIFï¼‰"):
        st.subheader("VIF æ£€éªŒï¼ˆ>5/10 éœ€è­¦æƒ•ï¼‰")
        from statsmodels.stats.outliers_influence import variance_inflation_factor
        Xv = sm.add_constant(df[pass_cols])
        vifs = []
        for k in range(1, Xv.shape[1]):  # skip const
            vifs.append([Xv.columns[k], variance_inflation_factor(Xv.values, k)])
        vif_df = pd.DataFrame(vifs, columns=["å˜é‡","VIF"]).sort_values("VIF", ascending=False)
        st.dataframe(vif_df.style.format("{:.2f}"))
        register_table("vif", vif_df)

    # 3) éçº¿æ€§ï¼ˆåˆ†æ®µ/å•è°ƒï¼‰
    if st.checkbox("â‘¢ éçº¿æ€§ä¸å•è°ƒæ€§æ£€éªŒï¼ˆåˆ†æ®µï¼‰"):
        st.subheader("é€šè¿‡é¡¹è®¡æ•° vs æ»¡æ„ç‡ï¼ˆåˆ†æ®µï¼‰")
        df["pass_sum"] = df[pass_cols].sum(axis=1)
        g = df.groupby("pass_sum")["satisfied"].mean().reset_index()
        fig, ax = plt.subplots(figsize=(6.5,4), dpi=140)
        ax.plot(g["pass_sum"], g["satisfied"], marker="o")
        ax.set_title("Satisfaction by Number of Passed QC Items")
        ax.set_xlabel("#Passed Items"); ax.set_ylabel("Satisfaction Rate")
        st.pyplot(fig)
        register_fig("nonlinear_passsum", fig)
        register_table("passsum_curve", g)

    # 4) æ­£åˆ™åŒ– + äº¤äº’æœç´¢ï¼ˆL1/L2ï¼‰
    if st.checkbox("â‘£ æ­£åˆ™åŒ–é€»è¾‘å›å½’ï¼ˆå«å¤§è§„æ¨¡äº¤äº’æœç´¢ï¼‰"):
        st.subheader("L1/L2 Logistic with Interactions")
        poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)
        Xp = poly.fit_transform(df[pass_cols])
        feat_names = poly.get_feature_names_out(pass_cols)
        scaler = StandardScaler()
        Xs = scaler.fit_transform(Xp)
        # L1
        lr_l1 = LogisticRegression(penalty="l1", solver="liblinear", max_iter=2000)
        lr_l1.fit(Xs, y)
        coef_l1 = pd.Series(lr_l1.coef_[0], index=feat_names).sort_values(ascending=False)
        nz = coef_l1[coef_l1!=0]
        st.write("L1 non-zero features:"); st.dataframe(nz.to_frame("coef"))
        register_table("l1_nonzero", nz.to_frame("coef"))
        # L2
        lr_l2 = LogisticRegression(penalty="l2", solver="liblinear", max_iter=2000)
        lr_l2.fit(Xs, y)
        auc = roc_auc_score(y, lr_l2.predict_proba(Xs)[:,1])
        ap = average_precision_score(y, lr_l2.predict_proba(Xs)[:,1])
        st.write(f"AUC={auc:.3f}, AP={ap:.3f}")
        register_text("l2_metrics", f"AUC={auc:.3f}, AP={ap:.3f}")

    # 5) è‡ªä¸¾ç½®ä¿¡åŒºé—´ + FDR
    if st.checkbox("â‘¤ ç¨³å¥æ€§ï¼šBootstrap CI + FDR å¤šé‡æ£€éªŒ"):
        st.subheader("tæ£€éªŒå·®å¼‚çš„ Bootstrap ç½®ä¿¡åŒºé—´ & FDR æ ¡æ­£")
        rows = []
        for col in pass_cols:
            a = df[df[col]==1]["satisfied"]; b = df[df[col]==0]["satisfied"]
            if len(a)>20 and len(b)>20:
                diff, lo, hi = bootstrap_diff_rate(a,b, n_boot=1000)
                t, p = stats.ttest_ind(a,b, equal_var=False)
                rows.append([col, diff, lo, hi, p])
        robust_df = pd.DataFrame(rows, columns=["æŒ‡æ ‡é¡¹","å·®å¼‚","CI_lo","CI_hi","p"])
        if not robust_df.empty:
            mask = benjamini_hochberg(robust_df["p"].values, alpha=0.05)
            robust_df["FDR_significant"] = mask
        st.dataframe(robust_df)
        register_table("bootstrap_fdr", robust_df)

    # 6) è¯¯å·®åŸŸå››è±¡é™
    if st.checkbox("â‘¥ è¯¯å·®åŸŸå››è±¡é™ï¼šæ ‡å‡†ä¸æ„ŸçŸ¥åç¦»å®šä½"):
        st.subheader("å››è±¡é™åˆ†å¸ƒï¼ˆèšç„¦ FPï¼šé€šè¿‡ä½†ä¸æ»¡æ„ï¼›FNï¼šæœªé€šè¿‡ä½†æ»¡æ„ï¼‰")
        quad = pd.crosstab(df["overall_pass"], df["satisfied"], normalize=True).round(3)
        st.dataframe(quad)
        register_table("quadrant", quad)

    # 7) å¼‚è´¨æ€§ï¼šåˆ†å±‚æ¨¡å‹
    if st.checkbox("â‘¦ å¼‚è´¨æ€§ï¼šåˆ†ä¸šåŠ¡çº¿/æ¸ é“/é—®é¢˜ç±»å‹å»ºæ¨¡"):
        st.subheader("åˆ†å±‚ Logisticï¼ˆç¤ºä¾‹ï¼šbusiness_line / ticket_channel / case_classificationï¼‰")
        layered_out = []
        for dim in ["business_line", "ticket_channel", "case_classification"]:
            if dim in df.columns:
                for v in df[dim].dropna().unique().tolist()[:10]:
                    sub = df[df[dim]==v]
                    if len(sub)>50 and sub["satisfied"].nunique()>1:
                        Xs_ = sm.add_constant(sub[pass_cols])
                        try:
                            m = sm.Logit(sub["satisfied"], Xs_).fit(disp=False)
                            part = pd.DataFrame({"ç»´åº¦": dim, "å–å€¼": v,
                                                 "é¡¹": m.params.index[1:], "ç³»æ•°": m.params.values[1:], "p": m.pvalues.values[1:]})
                            layered_out.append(part)
                        except Exception:
                            pass
        if layered_out:
            layered_df = pd.concat(layered_out, ignore_index=True)
            st.dataframe(layered_df.sort_values(["ç»´åº¦","å–å€¼","ç³»æ•°"], ascending=[True,True,False]))
            register_table("layered_logit", layered_df)

    # 8) å› æœï¼šPSM
    if st.checkbox("â‘§ å› æœæ¨æ–­ï¼šå€¾å‘å¾—åˆ†åŒ¹é…ï¼ˆPSMï¼‰ä¼°è®¡å„é¡¹å¯¹æ»¡æ„åº¦çš„å› æœæå‡"):
        st.subheader("PSMï¼ˆæ¯ä¸ªQCé¡¹å•ç‹¬åšä¸€æ¬¡å¤„ç†ä¸å¯¹ç…§åŒ¹é…ï¼‰")
        ps_rows = []
        for col in pass_cols:
            covars = [c for c in pass_cols if c!=col]
            if len(covars)<1: continue
            lr = LogisticRegression(solver="liblinear")
            lr.fit(df[covars], df[col])
            ps = lr.predict_proba(df[covars])[:,1]
            data = df[[col, "satisfied"]].copy()
            data["ps"] = ps

            treat = data[data[col]==1].copy()
            ctrl = data[data[col]==0].copy()
            if len(treat)<10 or len(ctrl)<10: continue
            nn = NearestNeighbors(n_neighbors=1, metric="euclidean")
            nn.fit(ctrl[["ps"]].values)
            dist, idx = nn.kneighbors(treat[["ps"]].values)
            matched_ctrl = ctrl.iloc[idx.flatten()]
            att = treat["satisfied"].values.mean() - matched_ctrl["satisfied"].values.mean()
            ps_rows.append([col, att, len(treat), len(ctrl)])
        ps_df = pd.DataFrame(ps_rows, columns=["è´¨æ£€é¡¹","ATT(åŒ¹é…åæ»¡æ„åº¦æå‡)","treat_n","ctrl_n"])
        st.dataframe(ps_df.sort_values("ATT(åŒ¹é…åæ»¡æ„åº¦æå‡)", ascending=False))
        register_table("psm_att", ps_df)

    # 9) è¿‡ç¨‹è´¨é‡ç›‘æ§
    if st.checkbox("â‘¨ è¿‡ç¨‹è´¨é‡ç›‘æ§ï¼šSPC/CUSUM/EWMA"):
        st.subheader("SPCï¼ˆæ»šåŠ¨æ»¡æ„ç‡ï¼‰")
        fig = plot_spc(df["satisfied"].rolling(30, min_periods=10).mean().dropna(), "SPC: Rolling Satisfaction Rate")
        st.pyplot(fig)
        register_fig("spc_rolling", fig)

        st.subheader("CUSUMï¼ˆä¸Šå/ä¸‹åç´¯è®¡ï¼‰")
        series = df["satisfied"].rolling(30, min_periods=10).mean().dropna()
        if len(series)>5:
            target = series.mean()
            pos = np.maximum(0, (series-target))
            neg = np.maximum(0, (target-series))
            pos_cusum = pos.cumsum(); neg_cusum = neg.cumsum()
            fig2, ax2 = plt.subplots(figsize=(9,4.5), dpi=140)
            ax2.plot(pos_cusum, label="Positive CUSUM"); ax2.plot(neg_cusum, label="Negative CUSUM")
            ax2.set_title("CUSUM of Satisfaction Deviation"); ax2.legend(); ax2.grid(alpha=0.25, linestyle="--")
            st.pyplot(fig2)
            register_fig("cusum", fig2)

    # 10) ç›®æ ‡å»ºæ¨¡ï¼šé¢„æµ‹ + SHAP
    if st.checkbox("â‘© ç›®æ ‡å»ºæ¨¡ï¼šæ»¡æ„åº¦é¢„æµ‹ + å¯è§£é‡Šæ€§ï¼ˆSHAPï¼‰"):
        st.subheader("é¢„æµ‹æ»¡æ„åº¦ï¼ˆä»…QCç‰¹å¾ï¼‰")
        Xbin = df[pass_cols+interaction_cols].copy()
        scaler = StandardScaler()
        Xs = scaler.fit_transform(Xbin)
        clf = LogisticRegression(max_iter=2000, solver="liblinear")
        clf.fit(Xs, y)
        prob = clf.predict_proba(Xs)[:,1]
        auc = roc_auc_score(y, prob); ap = average_precision_score(y, prob)
        st.write(f"AUC={auc:.3f}, AP={ap:.3f}")
        register_text("clf_metrics", f"AUC={auc:.3f}, AP={ap:.3f}")

        fpr, tpr, _ = roc_curve(y, prob)
        fig, ax = plt.subplots(figsize=(6,4), dpi=140)
        ax.plot(fpr, tpr); ax.plot([0,1],[0,1], linestyle="--", color="gray")
        ax.set_title("ROC Curve"); ax.set_xlabel("FPR"); ax.set_ylabel("TPR")
        st.pyplot(fig); register_fig("roc", fig)

        pr, rc, _ = precision_recall_curve(y, prob)
        fig2, ax2 = plt.subplots(figsize=(6,4), dpi=140)
        ax2.plot(rc, pr); ax2.set_title("Precision-Recall Curve"); ax2.set_xlabel("Recall"); ax2.set_ylabel("Precision")
        st.pyplot(fig2); register_fig("pr_curve", fig2)

        try:
            import shap
            explainer = shap.LinearExplainer(clf, Xs)
            shap_values = explainer.shap_values(Xs)
            top_idx = np.argsort(np.abs(shap_values).mean(axis=0))[::-1][:20]
            top_features = pd.Series(np.abs(shap_values).mean(axis=0)[top_idx],
                                     index=pd.Index(np.array(pass_cols+interaction_cols)[top_idx], name="Feature"))
            st.dataframe(top_features.to_frame("mean|SHAP|"))
            register_table("shap_top", top_features.to_frame("mean|SHAP|"))
        except Exception as e:
            st.info(f"SHAP ä¸å¯ç”¨ï¼š{e}")

    # 11) ç”Ÿå­˜åˆ†æï¼ˆå¯é€‰ï¼‰
    if st.checkbox("â‘ª ç”Ÿå­˜åˆ†æï¼ˆå¤„ç†è€—æ—¶å¯¹æ»¡æ„åº¦çš„å½±å“ï¼‰"):
        st.subheader("è‹¥æœ‰å¤„ç†æ—¶é•¿å­—æ®µï¼ˆå¦‚ï¼šè§£å†³è€—æ—¶hourï¼‰ï¼Œå¯åšKMæ›²çº¿")
        if "handle_hours" in df.columns and "resolved" in df.columns:
            try:
                from lifelines import KaplanMeierFitter
                km = KaplanMeierFitter()
                T = df["handle_hours"]; E = df["resolved"]
                fig, ax = plt.subplots(figsize=(7,4), dpi=140)
                km.fit(T, event_observed=E, label="All"); km.plot(ax=ax)
                ax.set_title("KM Curve of Resolution Time"); ax.set_xlabel("Hours"); ax.set_ylabel("Survival")
                st.pyplot(fig); register_fig("km_curve", fig)
            except Exception as e:
                st.info(f"éœ€è¦ lifelines åŒ…ï¼š{e}")
        else:
            st.info("æœªæ£€æµ‹åˆ° 'handle_hours' ä¸ 'resolved' å­—æ®µï¼Œè·³è¿‡ã€‚")

    # 12) ç­–ç•¥ä¼˜åŒ–å»ºè®®ï¼ˆåŸºäºä»¥ä¸Šåˆ†æå³æ—¶ç”Ÿæˆï¼‰
    st.subheader("ğŸ“Œ è´¨æ£€æ ‡å‡†ä¸æŠ½æ£€ç­–ç•¥ä¼˜åŒ–ï¼ˆè‡ªåŠ¨å»ºè®®ï¼‰")
    try:
        sig = coef_df[coef_df["på€¼"]<0.05].copy()
        if not sig.empty:
            sig["æƒé‡å€™é€‰"] = (sig["å›å½’ç³»æ•°"].abs()/sig["å›å½’ç³»æ•°"].abs().sum()).round(3)
            st.markdown("**1) æŒ‡æ ‡æƒé‡å»ºè®®ï¼ˆå½’ä¸€åŒ–ç³»æ•°ï¼‰ï¼š**")
            st.dataframe(sig[["æŒ‡æ ‡é¡¹","å›å½’ç³»æ•°","på€¼","æƒé‡å€™é€‰"]])
            register_table("weight_candidate", sig[["æŒ‡æ ‡é¡¹","å›å½’ç³»æ•°","på€¼","æƒé‡å€™é€‰"]])
        else:
            st.info("æš‚æ— æ˜¾è‘—å•é¡¹ï¼Œå»ºè®®æ‰©å¤§æ ·æœ¬ã€‚")

        top_inter = coef_inter_df[(coef_inter_df["på€¼"]<0.05) & (coef_inter_df["å˜é‡"].str.contains("Ã—"))].head(3)
        st.markdown("**2) ç»„åˆè”æ£€ï¼ˆäº¤äº’æ˜¾è‘— Top3ï¼‰ï¼š**")
        if not top_inter.empty:
            st.dataframe(top_inter); register_table("top_interactions", top_inter)
        else:
            st.info("æš‚æ— æ˜¾è‘—äº¤äº’ã€‚")

        st.markdown("""
        **3) æŠ½æ£€ç­–ç•¥ï¼š**  
        - å¯¹ **FP åŒºåŸŸï¼ˆoverall_pass=1ï¼Œsatisfied=0ï¼‰** æé«˜å¤æ ¸æ¦‚ç‡ï¼ˆå¦‚ï¼š+30%ï¼‰ï¼Œé‡ç‚¹å®¡æŸ¥ `æœåŠ¡æ€åº¦` ä¸ `è§£å†³æ–¹æ¡ˆ`ï¼›  
        - å¯¹ **FN åŒºåŸŸï¼ˆoverall_pass=0ï¼Œsatisfied=1ï¼‰** å¤ç›˜æ ‡å‡†æ˜¯å¦â€œè¿‡ä¸¥/ä¸ä½“éªŒæ— å…³â€ï¼Œé€‚åº¦ä¸‹è°ƒè¯¥é¡¹é˜ˆå€¼æˆ–å¼±åŒ–æƒé‡ï¼›  
        - å¯¹æ˜¾è‘—äº¤äº’é¡¹ï¼ˆå¦‚ `solution Ã— response_speed`ï¼‰è¦æ±‚**è”åˆé€šè¿‡**æˆ–åˆ†é…æ›´é«˜åˆæˆæƒé‡ï¼›
        """)
        register_text("strategy_notes", "æŠ½æ£€ç­–ç•¥ä¸æƒé‡/è”æ£€å»ºè®®å·²è¾“å‡ºã€‚")
    except Exception as e:
        st.warning(f"ç­–ç•¥ç”Ÿæˆå¤±è´¥ï¼š{e}")

    # ============ æ—¶é—´è¶‹åŠ¿ ============
    st.subheader("æ—¶é—´è¶‹åŠ¿åˆ†æï¼ˆæŒ‰æœˆï¼‰")
    time_col = "è´¨æ£€æ—¶é—´" if "è´¨æ£€æ—¶é—´" in df.columns else None
    if time_col:
        dt_ser = pd.to_datetime(df[time_col], errors="coerce")
        df["month"] = dt_ser.dt.to_period("M").astype(str)
        trend = (df.dropna(subset=["month"])
                   .groupby("month")[["satisfied","overall_pass"]]
                   .mean().reset_index().sort_values("month"))
        trend["Satisfaction (%)"] = (trend["satisfied"]*100).round(2)
        trend["Pass Rate (%)"] = (trend["overall_pass"]*100).round(2)
        fig_trend, ax = plt.subplots(figsize=(9,4.5), dpi=140)
        x = np.arange(len(trend))
        ax.plot(x, trend["Satisfaction (%)"], marker="o", label="Satisfaction (%)")
        ax.plot(x, trend["Pass Rate (%)"], marker="o", label="Pass Rate (%)")
        ax.set_xticks(x); ax.set_xticklabels(trend["month"], rotation=30, ha="right")
        ax.set_title("Monthly Trend: Satisfaction vs Pass Rate"); ax.set_ylabel("Percentage (%)")
        ax.legend(); ax.grid(alpha=0.25, linestyle="--", linewidth=0.5)
        st.pyplot(fig_trend)
        register_fig("trend_lines", fig_trend)
        register_table("trend_table", trend)

    # ============ åˆ†ä¸šåŠ¡çº¿ / æ¸ é“ ============
    if "business_line" in df.columns:
        st.subheader("åˆ†ä¸šåŠ¡çº¿ï¼šæ•´ä½“é€šè¿‡ç‡ vs æ»¡æ„ç‡")
        biz = (df.groupby("business_line")[pass_cols+["overall_pass","satisfied"]]
                 .mean().apply(lambda x: round(x*100,2)).reset_index())
        st.dataframe(biz[["business_line","overall_pass","satisfied"]])
        register_table("biz_overview", biz)
        fig_biz, ax_biz = plt.subplots(figsize=(8,4.5), dpi=140)
        sns.scatterplot(data=biz, x="overall_pass", y="satisfied", hue="business_line", s=120, ax=ax_biz)
        ax_biz.set_xlabel("Overall Pass Rate (%)"); ax_biz.set_ylabel("Satisfaction Rate (%)")
        ax_biz.set_title("Business Line: Pass vs Satisfaction")
        st.pyplot(fig_biz); register_fig("biz_scatter", fig_biz)

    if "ticket_channel" in df.columns:
        st.subheader("åˆ†æ¸ é“ï¼šæ•´ä½“é€šè¿‡ç‡ vs æ»¡æ„ç‡")
        ch = (df.groupby("ticket_channel")[pass_cols+["overall_pass","satisfied"]]
                .mean().apply(lambda x: round(x*100,2)).reset_index())
        st.dataframe(ch[["ticket_channel","overall_pass","satisfied"]])
        register_table("channel_overview", ch)
        fig_ch, ax_ch = plt.subplots(figsize=(8,4.5), dpi=140)
        sns.scatterplot(data=ch, x="overall_pass", y="satisfied", hue="ticket_channel", s=120, ax=ax_ch)
        ax_ch.set_xlabel("Overall Pass Rate (%)"); ax_ch.set_ylabel("Satisfaction Rate (%)")
        ax_ch.set_title("Channel: Pass vs Satisfaction")
        st.pyplot(fig_ch); register_fig("channel_scatter", fig_ch)

    # ============ è‡ªåŠ¨ç»“è®º ============
    st.success("âœ… å…¨éƒ¨åˆ†æå®Œæˆã€‚")
    st.subheader("ğŸ“Š è‡ªåŠ¨ç»“è®ºï¼ˆé¢å‘æ ‡å‡†ä¼˜åŒ–ï¼‰")
    try:
        sig_items = coef_df[coef_df["på€¼"]<0.05]
        if not sig_items.empty:
            key_item = sig_items.sort_values("å›å½’ç³»æ•°", ascending=False).iloc[0]["æŒ‡æ ‡é¡¹"]
            lowest_item = sig_items.sort_values("å›å½’ç³»æ•°", ascending=True).iloc[0]["æŒ‡æ ‡é¡¹"]
            concl = f"""
**1ï¸âƒ£ æœ€å…³é”®æå‡é¡¹ï¼š** `{key_item}` â†’ å»ºè®®æé«˜æƒé‡æˆ–ç»†åŒ–äºŒçº§å‡†åˆ™ï¼ˆåˆ†æ¡£/ç¤ºä¾‹åº“ï¼‰ã€‚  
**2ï¸âƒ£ å¯èƒ½è¿‡ä¸¥/å®šä¹‰æ¨¡ç³Šï¼š** `{lowest_item}` â†’ å»ºè®®é™ä½é˜ˆå€¼æˆ–ä»â€œå¿…è¿‡â€æ”¹ä¸ºâ€œåŠ åˆ†é¡¹â€ã€‚  
**3ï¸âƒ£ è‹¥å‡ºç°â€œé€šè¿‡â†‘ä½†æ»¡æ„â†“â€** â†’ æ ‡å‡†åç¦»å®¢æˆ·æ„ŸçŸ¥ï¼Œä¼˜å…ˆå¤æ ¸ FP åŒºåŸŸæ ·æœ¬å¹¶ä¿®è®¢è§„åˆ™ã€‚  
**4ï¸âƒ£ å¯¹æ˜¾è‘—äº¤äº’é¡¹** â†’ é‡‡ç”¨â€œè”åˆé€šè¿‡â€æˆ–â€œè”åŠ¨åŠ æƒâ€ï¼Œé¿å…å•ç‚¹è¾¾æ ‡æ©ç›–é—®é¢˜ã€‚  
"""
            st.markdown(concl)
            register_text("final_conclusion", concl)
        else:
            st.info("æš‚æ— æ˜¾è‘—é¡¹ï¼Œå»ºè®®æ‰©å¤§æ ·æœ¬æˆ–å»¶é•¿è§‚æµ‹çª—å£ã€‚")
    except Exception as e:
        st.warning(f"ç»“è®ºç”Ÿæˆå¤±è´¥ï¼š{e}")

    # ====================== â¬‡ï¸ å¯¼å‡ºæŠ¥å‘Šä¸åŸå§‹ç´ æï¼ˆDOCX / ZIPï¼‰ ======================
    st.markdown("---")
    st.header("å¯¼å‡ºæŠ¥å‘Š")
    st.caption("è¯´æ˜ï¼šè‹¥ç¯å¢ƒå·²å®‰è£… `python-docx` å°†ç”Ÿæˆ Word æŠ¥å‘Šï¼›åŒæ—¶æä¾› ZIPï¼ˆåŒ…å« CSV è¡¨æ ¼ä¸ PNG å›¾ç‰‡ï¼‰ã€‚")

    colA, colB = st.columns(2)

    with colA:
        # å¯¼å‡º ZIPï¼ˆè¡¨æ ¼CSV + å›¾åƒPNGï¼‰
        if st.button("æ‰“åŒ…å¯¼å‡º ZIPï¼ˆè¡¨+å›¾ï¼‰"):
            zip_buffer = BytesIO()
            with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                # CSVs
                for name, df_tbl in table_registry.items():
                    csv_bytes = df_tbl.to_csv(index=True).encode("utf-8-sig")
                    zf.writestr(f"tables/{name}.csv", csv_bytes)
                # PNG figures
                for name, fig in fig_registry.items():
                    img_bytes = BytesIO()
                    fig.savefig(img_bytes, format="png", dpi=200, bbox_inches="tight")
                    img_bytes.seek(0)
                    zf.writestr(f"figures/{name}.png", img_bytes.read())
                # ç»“è®ºæ–‡æœ¬
                all_txt = "\n\n".join([f"[{k}]\n{text_registry[k]}" for k in text_registry])
                zf.writestr("summary/conclusions.txt", all_txt.encode("utf-8"))

            zip_buffer.seek(0)
            ts = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
            st.download_button(
                label="ä¸‹è½½ ZIP",
                data=zip_buffer,
                file_name=f"QC_Satisfaction_Report_{ts}.zip",
                mime="application/zip"
            )

    with colB:
        # å¯¼å‡º DOCXï¼ˆéœ€è¦ python-docxï¼‰
        try:
            from docx import Document
            from docx.shared import Inches, Pt
            from docx.enum.text import WD_ALIGN_PARAGRAPH

            if st.button("å¯¼å‡º Wordï¼ˆ.docxï¼‰æŠ¥å‘Š"):
                doc = Document()
                doc.add_heading("è´¨æ£€ä¸æ»¡æ„åº¦åˆ†ææŠ¥å‘Š", 0)
                p = doc.add_paragraph(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                p.alignment = WD_ALIGN_PARAGRAPH.LEFT

                # ç« èŠ‚ï¼šç»“è®º
                doc.add_heading("ä¸€ã€è‡ªåŠ¨ç»“è®ºï¼ˆé¢å‘æ ‡å‡†ä¼˜åŒ–ï¼‰", level=1)
                doc.add_paragraph(text_registry.get("final_conclusion", "ï¼ˆæœ¬æ¬¡æœªç”Ÿæˆæ˜¾è‘—æ€§ç»“è®ºï¼Œå»ºè®®æ‰©å¤§æ ·æœ¬ï¼‰"))

                # ç« èŠ‚ï¼šå…³é”®è¡¨æ ¼ï¼ˆç²¾é€‰Topï¼‰
                doc.add_heading("äºŒã€å…³é”®è¡¨æ ¼", level=1)
                key_tables = [
                    ("summary_rates", "å„é¡¹é€šè¿‡ç‡ä¸æ»¡æ„ç‡ï¼ˆ%ï¼‰"),
                    ("logit_single", "Logisticå›å½’ï¼ˆå•é¡¹ï¼‰"),
                    ("interaction_ttest", "ä¸¤ä¸¤äº¤äº’æ˜¾è‘—æ€§"),
                    ("logit_interactions", "äº¤äº’é¡¹å›å½’ï¼ˆå«ç³»æ•°ï¼‰"),
                    ("weight_candidate", "æƒé‡å€™é€‰ï¼ˆæŒ‰å›å½’ç³»æ•°å½’ä¸€ï¼‰"),
                    ("trend_table", "æœˆåº¦è¶‹åŠ¿"),
                ]
                for key, title in key_tables:
                    if key in table_registry:
                        doc.add_heading(title, level=2)
                        df_tbl = table_registry[key]
                        # å†™å…¥è¡¨æ ¼
                        t = doc.add_table(rows=1, cols=len(df_tbl.columns)+1)
                        t.style = "Light List Accent 1"
                        hdr_cells = t.rows[0].cells
                        hdr_cells[0].text = ""
                        for i, c in enumerate(df_tbl.columns):
                            hdr_cells[i+1].text = str(c)
                        for idx, row in df_tbl.iterrows():
                            cells = t.add_row().cells
                            cells[0].text = str(idx)
                            for j, c in enumerate(df_tbl.columns):
                                cells[j+1].text = str(row[c])
                        doc.add_paragraph("")  # spacing

                # ç« èŠ‚ï¼šå…³é”®å›¾åƒ
                doc.add_heading("ä¸‰ã€æ ¸å¿ƒå›¾è¡¨", level=1)
                key_figs = [
                    ("corr_matrix", "ç›¸å…³æ€§çƒ­åŠ›å›¾"),
                    ("logit_coef_bar", "Logistic ç³»æ•°å½±å“æ¡å½¢å›¾"),
                    ("trend_lines", "æœˆåº¦è¶‹åŠ¿"),
                    ("biz_scatter", "ä¸šåŠ¡çº¿ï¼šé€šè¿‡ç‡ vs æ»¡æ„ç‡"),
                    ("channel_scatter", "æ¸ é“ï¼šé€šè¿‡ç‡ vs æ»¡æ„ç‡"),
                ]
                for key, title in key_figs:
                    if key in fig_registry:
                        doc.add_heading(title, level=2)
                        fig = fig_registry[key]
                        img_bytes = BytesIO()
                        fig.savefig(img_bytes, format="png", dpi=200, bbox_inches="tight")
                        img_bytes.seek(0)
                        doc.add_picture(img_bytes, width=Inches(6.2))
                        doc.add_paragraph("")

                # ä¿å­˜åˆ°å†…å­˜å¹¶ä¸‹è½½
                doc_bytes = BytesIO()
                doc.save(doc_bytes)
                doc_bytes.seek(0)
                ts = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    label="ä¸‹è½½ Word æŠ¥å‘Š",
                    data=doc_bytes,
                    file_name=f"QC_Satisfaction_Report_{ts}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
        except Exception as e:
            st.info(f"æœªæ£€æµ‹åˆ° python-docx æˆ–å¯¼å‡ºå¤±è´¥ï¼š{e}\nå¦‚éœ€ Word å¯¼å‡ºï¼špip install python-docx")

else:
    st.info("è¯·ä¸Šä¼ å¤šä¸ªè´¨æ£€æ–‡ä»¶åå¼€å§‹åˆ†æã€‚")
